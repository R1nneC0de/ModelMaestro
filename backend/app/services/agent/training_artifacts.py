"""
Training artifact management.

Handles storage and retrieval of model artifacts, preprocessing artifacts,
and training reports.
"""

import json
import logging
from typing import Dict, Any
from datetime import datetime

from google.cloud import storage

from app.core.config import settings

logger = logging.getLogger(__name__)


class TrainingArtifactManager:
    """Manager for training artifacts and reports."""
    
    def __init__(self, bucket_name: str):
        """
        Initialize artifact manager.
        
        Args:
            bucket_name: GCS bucket name
        """
        self.bucket_name = bucket_name
        self.client = storage.Client(project=settings.GOOGLE_CLOUD_PROJECT)
        self.bucket = self.client.bucket(bucket_name)
    
    async def store_artifacts(
        self,
        dataset_id: str,
        job_info: Dict[str, Any],
        config: Any,
        preprocessing_metadata: Dict[str, Any]
    ) -> Dict[str, str]:
        """
        Store model and preprocessing artifacts to GCS.
        
        Args:
            dataset_id: Dataset identifier
            job_info: Job information
            config: Model configuration
            preprocessing_metadata: Preprocessing metadata from Step 3
            
        Returns:
            Dictionary with artifact URIs
        """
        # Model URI
        if job_info.get("training_type") == "automl_tabular":
            model_uri = f"projects/{settings.GOOGLE_CLOUD_PROJECT}/locations/{settings.VERTEX_AI_LOCATION}/models/{job_info['job_id']}"
        else:
            model_uri = f"gs://{self.bucket_name}/models/{dataset_id}/artifacts/model.pkl"
        
        # Store preprocessing artifacts
        prep_path = f"models/{dataset_id}/preprocessing"
        
        # Store preprocessing metadata
        metadata_blob = self.bucket.blob(f"{prep_path}/metadata.json")
        metadata_blob.upload_from_string(
            json.dumps(preprocessing_metadata, indent=2),
            content_type="application/json"
        )
        
        # Store model config
        config_blob = self.bucket.blob(f"{prep_path}/model_config.json")
        config_blob.upload_from_string(
            json.dumps(config.to_dict(), indent=2),
            content_type="application/json"
        )
        
        prep_uri = f"gs://{self.bucket_name}/{prep_path}"
        
        logger.info(
            f"Artifacts stored: model_uri={model_uri}, prep_uri={prep_uri}"
        )
        
        return {
            "model_uri": model_uri,
            "prep_uri": prep_uri
        }
    
    async def generate_training_report(
        self,
        dataset_id: str,
        config: Any,
        metrics: Dict[str, float],
        duration_seconds: float,
        job_info: Dict[str, Any]
    ) -> str:
        """
        Generate training report in Markdown format.
        
        Args:
            dataset_id: Dataset identifier
            config: Model configuration
            metrics: Training metrics
            duration_seconds: Training duration
            job_info: Job information
            
        Returns:
            GCS URI to the report
        """
        # Generate report content
        report = f"""# Training Report

## Model Information
- **Architecture**: {config.architecture}
- **Training Type**: {config.vertex_ai_type}
- **Job ID**: {job_info['job_id']}
- **Dataset ID**: {dataset_id}

## Training Configuration
- **Primary Metric**: {config.primary_metric}
- **Random Seed**: {config.split_config.random_seed}
- **Train/Val/Test Split**: {config.split_config.train_ratio}/{config.split_config.val_ratio}/{config.split_config.test_ratio}

### Hyperparameters
```json
{json.dumps(config.hyperparameters, indent=2)}
```

## Performance Metrics
"""
        
        for metric_name, metric_value in metrics.items():
            report += f"- **{metric_name}**: {metric_value:.4f}\n"
        
        report += f"""
## Acceptance Thresholds
"""
        
        for threshold_name, threshold_value in config.acceptance_thresholds.items():
            actual_value = metrics.get(threshold_name, 0.0)
            passed = "✓" if actual_value >= threshold_value else "✗"
            report += f"- **{threshold_name}**: {threshold_value:.4f} {passed} (actual: {actual_value:.4f})\n"
        
        report += f"""
## Training Details
- **Duration**: {duration_seconds:.2f} seconds ({duration_seconds/60:.2f} minutes)
- **Started**: {job_info.get('created_at', 'N/A')}
- **Completed**: {datetime.utcnow().isoformat()}

## Model Selection Reasoning
{config.reasoning}

---
*Generated by Agentic Model Training Platform*
"""
        
        # Upload report to GCS
        report_path = f"models/{dataset_id}/reports/training_report.md"
        report_blob = self.bucket.blob(report_path)
        report_blob.upload_from_string(report, content_type="text/markdown")
        
        report_uri = f"gs://{self.bucket_name}/{report_path}"
        
        logger.info(f"Training report generated: {report_uri}")
        
        return report_uri
